apiVersion: v1
kind: Pod
metadata:
  name: rocm-pytorch-test
spec:
  containers:
    - image: docker.io/rocm/pytorch:latest
      name: pytorch-test
      command: ["/bin/bash", "-c"]
      args:
        - |
          echo "=== ROCm Device Check ==="
          rocminfo | grep -A5 "Agent 2"
          echo ""
          echo "=== PyTorch GPU Test ==="
          python3 -c "
          import torch
          print(f'PyTorch version: {torch.__version__}')
          print(f'ROCm available: {torch.cuda.is_available()}')
          if torch.cuda.is_available():
              print(f'GPU count: {torch.cuda.device_count()}')
              print(f'GPU name: {torch.cuda.get_device_name(0)}')
              print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')
              print('')
              print('=== Running simple matrix multiplication test ===')
              x = torch.rand(5000, 5000).cuda()
              y = torch.rand(5000, 5000).cuda()
              import time
              start = time.time()
              z = torch.matmul(x, y)
              torch.cuda.synchronize()
              end = time.time()
              print(f'Matrix multiplication (5000x5000) took {(end-start)*1000:.2f}ms')
              print('GPU compute test: SUCCESS!')
          else:
              print('ERROR: GPU not available to PyTorch')
              exit(1)
          "
      resources:
        limits:
          amd.com/gpu: 1
        requests:
          amd.com/gpu: 1
  restartPolicy: Never
